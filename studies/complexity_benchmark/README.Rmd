---
output: 
  github_document:
    toc: false
    fig_width: 10.08
    fig_height: 6
tags: [r, complexity]
vignette: >
  %\VignetteIndexEntry{README}
  \usepackage[utf8]{inputenc}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
bibliography: bibliography.bib
csl: utils/apa.csl
---

```{r, echo = FALSE, warning=FALSE, message=FALSE}
# options and parameters
options(digits = 3)

knitr::opts_chunk$set(
  collapse = TRUE,
  dpi = 450,
  fig.path = "../../studies/complexity_benchmark/figures/"
)
```



<!-- # Benchmarking and Analysis of Complexity Measures -->
<!-- # Measuring Chaos: Complexity and Fractal Physiology using NeuroKit2 -->
# Measuring Chaos with NeuroKit2, and an Empirical Relationship between Complexity Indices

*This study can be referenced by* [*citing the package and the documentation*](https://neuropsychology.github.io/NeuroKit/cite_us.html).

**We'd like to improve this study, but unfortunately we currently don't have the time. If you want to help to make it happen, please contact us!**

## Introduction

Complexity is an umbrella term for concepts derived from information theory, chaos theory, and fractal mathematics, used to quantify the unpredictability and randomness of a signal. Using these tools to characterize signals has shown promising results in physiology in the assessment and diagnostic of the health and state of living systems (a subfield referred to as "fractal physiology").

There has been a large and accelerating increase in the number of complexity indices in the past few decades. They are usually mathematically well-defined and theoretically promising. However, few empirical data exist to understand their differences and similarities. One of the contributing factor is the lack of free, open-source, and easy to use software for computing various complexity indices. Indeed, most of them are described mathematically in journal articles, and reusable code is seldom made available.

The goal for NeuroKit is to provide the most comprehensive, accurate and fast pure Python implementations of complexity indices (fractal dimension, entropy, etc.).

In this study, we will compute a vast amount of complexity indices on various types of signals, with varying degrees of noise. We will then empirically compare the various metrics and their relationship.
 


## Methods

### Data Generation

The script to generate the data can be found at ...

Generated 5 types of signals, to which we added different types of noise.

```{r message=FALSE, warning=FALSE, fig.height=20, fig.width=12}
library(tidyverse)
library(easystats)
library(patchwork)

df <- read.csv("data_Signals.csv") |>
  mutate(
    Method = as.factor(Method),
    Noise = as.factor(Noise),
    Intensity = as.factor(insight::format_value(Noise_Intensity))
  )

df <- df |>
  filter(Intensity %in% levels(df$Intensity)[c(1, round(length(levels(df$Intensity)) / 2), length(levels(df$Intensity)))])

make_plot <- function(method = "Random-Walk", title = "Random-Walk", color = "red") {
  df |>
    filter(Method == method) |>
    ggplot(aes(x = Duration, y = Signal)) +
    geom_line(color = color) +
    ggside::geom_ysidedensity(aes(x = stat(density))) +
    facet_grid(Intensity ~ Noise, labeller = label_both) +
    labs(y = NULL, title = title) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5),
      ggside.panel.border = element_blank(),
      ggside.panel.grid = element_blank(),
      ggside.panel.background = element_blank()
    )
}

p1 <- make_plot(method = "Random-Walk", title = "Random-Walk", color = "red")
p2 <- make_plot(method = "lorenz_10_2.5_28", title = "Lorenz (sigma=10, beta=2.5, rho=28)", color = "blue")
p3 <- make_plot(method = "lorenz_20_2_30", title = "Lorenz (sigma=20, beta=2, rho=30)", color = "green")
p4 <- make_plot(method = "oscillatory", title = "Oscillatory", color = "orange")
p5 <- make_plot(method = "fractal", title = "Fractal", color = "purple")

p1 / p2 / p3 / p4 / p5 + patchwork::plot_annotation(title = "Examples of Simulated Signals", theme = theme(plot.title = element_text(face = "bold", hjust = 0.5)))
```


## Results


```{r message=FALSE, warning=FALSE, results='hide'}
df <- read.csv("data_Complexity.csv") |>
  mutate(Method = as.factor(Method))

# Show and filter out NaNs
df[is.na(df$Result), "Index"]
df <- filter(df, !is.na(Result))

df[is.infinite(df$Result), "Index"]
df <- filter(df, !is.infinite(Result))

df <- df |>
  group_by(Index) |>
  standardize(select = "Result") |>
  ungroup()
```

```{r message=FALSE, warning=FALSE, include=FALSE}
colors <- c(
  "SD" = "red",
  "Noise" = "red",
  "Length" = "red",
  "Random" = "red",
  "PFD (A)" = "#2196F3",
  "PFD (B)" = "#2196F3",
  "PFD (C)" = "#2196F3",
  "PFD (D)" = "#2196F3",
  "PFD (r)" = "#2196F3",
  "PFD (3)" = "#2196F3",
  "PFD (10)" = "#2196F3",
  "PFD (100)" = "#2196F3",
  "PFD (1000)" = "#2196F3",
  "KFD" = "#2196F3",
  "SFD" = "#2196F3",
  "SDAFD" = "#2196F3",
  "NLDFD" = "#2196F3",
  "PSDFD (Voss1998)" = "#2196F3",
  "PSDFD (Hasselman2013)" = "#2196F3",
  "HFD" = "#2196F3",
  "SVDEn" = "#E91E63",
  "K2En" = "#E91E63",
  "AttEn" = "#E91E63",
  "PhasEn (4)" = "#E91E63",
  "PhasEn (8)" = "#E91E63",
  "GridEn (3)" = "#E91E63",
  "GridEn (10)" = "#E91E63",
  "DiffEn" = "#E91E63",
  "DistrEn" = "#E91E63",
  "ApEn" = "#E91E63",
  "cApEn" = "#E91E63",
  "PEn" = "#E91E63",
  "WPEn" = "#E91E63",
  "SampEn" = "#E91E63",
  "FuzzyEn" = "#E91E63",
  "FuzzyApEn" = "#E91E63",
  "FuzzycApEn" = "#E91E63",
  "MSEn" = "#E91E63",
  "CMSEn" = "#E91E63",
  "RCMSEn" = "#E91E63",
  "MMSEn" = "#E91E63",
  "IMSEn" = "#E91E63",
  "MSApEn" = "#E91E63",
  "MSPEn" = "#E91E63",
  "CMSPEn" = "#E91E63",
  "MMSPEn" = "#E91E63",
  "IMSPEn" = "#E91E63",
  "MSWPEn" = "#E91E63",
  "CMSWPEn" = "#E91E63",
  "MMSWPEn" = "#E91E63",
  "IMSWPEn" = "#E91E63",
  "CPEn" = "#E91E63",
  "CWPEn" = "#E91E63",
  "CRPEn" = "#E91E63",
  "BubbEn" = "#E91E63",
  "CoSiEn" = "#E91E63",
  "MSCoSiEn" = "#E91E63",
  "IncrEn" = "#E91E63",
  "MSIncrEn" = "#E91E63",
  "SlopEn" = "#E91E63",
  "SlopEn (7)" = "#E91E63",
  "MSSlopEn" = "#E91E63",
  "SyDyEn" = "#E91E63",
  "MSSyDyEn" = "#E91E63",
  "MMSyDyEn" = "#E91E63",
  "DispEn" = "#E91E63",
  "DispEn (fluctuation)" = "#E91E63",
  "FuzzyMSEn" = "#E91E63",
  "FuzzyCMSEn" = "#E91E63",
  "FuzzyRCMSEn" = "#E91E63",
  "FuzzyMMSEn" = "#E91E63",
  "FuzzyIMSEn" = "#E91E63",
  "ShanEn (A)" = "#E91E63",
  "ShanEn (B)" = "#E91E63",
  "ShanEn (C)" = "#E91E63",
  "ShanEn (D)" = "#E91E63",
  "ShanEn (r)" = "#E91E63",
  "ShanEn (3)" = "#E91E63",
  "ShanEn (10)" = "#E91E63",
  "ShanEn (100)" = "#E91E63",
  "ShanEn (1000)" = "#E91E63",
  "CREn (A)" = "#E91E63",
  "CREn (B)" = "#E91E63",
  "CREn (C)" = "#E91E63",
  "CREn (D)" = "#E91E63",
  "CREn (r)" = "#E91E63",
  "CREn (3)" = "#E91E63",
  "CREn (10)" = "#E91E63",
  "CREn (100)" = "#E91E63",
  "CREn (1000)" = "#E91E63",
  "EnofEn (3)" = "#E91E63",
  "EnofEn (5)" = "#E91E63",
  "EnofEn (9)" = "#E91E63",
  "RangeEn (A)" = "#E91E63",
  "RangeEn (Ac)" = "#E91E63",
  "RangeEn (B)" = "#E91E63",
  "SPEn (10)" = "#E91E63",
  "SPEn (50)" = "#E91E63",
  "SPEn (100)" = "#E91E63",
  "HEn" = "#E91E63",
  "KLEn" = "#E91E63",
  "KLEn (corrected)" = "#E91E63",
  "H (corrected)" = "#2196F3",
  "H (uncorrected)" = "#2196F3",
  "LZC" = "#2196F3",
  "PLZC" = "#2196F3",
  "MSLZC" = "#2196F3",
  "MSPLZC" = "#2196F3",
  "RR" = "#2196F3",
  "FI" = "#FF5722",
  "CD" = "#FF5722",
  "Hjorth" = "#FF5722",
  "LLE" = "#2196F3",
  "RQA_RecurrenceRate" = "#4CAF50",
  "RQA_Determinism" = "#4CAF50",
  "RQA_Laminarity" = "#4CAF50",
  "RQA_TrappingTime" = "#4CAF50",
  "RQA_Determinism_RecurrenceRate" = "#4CAF50",
  "RQA_Divergence" = "#4CAF50",
  "RQA_Laminarity_Determinism" = "#4CAF50",
  "RQA_RecurrenceRate" = "#4CAF50",
  "RQA_L" = "#4CAF50",
  "RQA_LEn" = "#4CAF50",
  "RQA_VMax" = "#4CAF50",
  "RQA_VEn" = "#4CAF50",
  "RQA_W" = "#4CAF50",
  "RQA_WMax" = "#4CAF50",
  "RQA_WEn" = "#4CAF50",
  "DFA" = "#4CAF50",
  "MFDFA_ExpRange" = "#4CAF50",
  "MFDFA_ExpMean" = "#4CAF50",
  "MFDFA_DimRange" = "#4CAF50",
  "MFDFA_DimMean" = "#4CAF50",
  "MFDFA_HMax" = "#4CAF50",
  "MFDFA_HDelta" = "#4CAF50",
  "MFDFA_HAR" = "#4CAF50"
)

# unique(df$Index)[!unique(df$Index) %in% names(colors)]
# names(colors)[!names(colors) %in% unique(df$Index)]
```




### Computation Time

```{r computation_time, message=FALSE, warning=FALSE, fig.width=16*1.25, fig.height=10*1.25, cache=TRUE}
order <- df |>
  group_by(Index) |>
  summarize(Duration = median(Duration)) |>
  arrange(Duration) |>
  mutate(Index = factor(Index, levels = Index))

df <- mutate(df, Index = fct_relevel(Index, as.character(order$Index)))

df |>
  filter(!Index %in% c("SD", "Length", "Noise", "Random")) |>
  mutate(Duration = Duration * 10000) |>
  ggplot(aes(x = Index, y = Duration)) +
  # geom_violin(aes(fill = Index)) +
  geom_hline(yintercept = 10**seq(0, 5, by = 2), linetype = "dotted", color = "#9E9E9E") +
  geom_hline(yintercept = 10**seq(1, 5, by = 2), color = "#9E9E9E") +
  ggdist::stat_slab(side = "bottom", aes(fill = Index), adjust = 3) +
  ggdist::stat_dotsinterval(aes(fill = Index, slab_size = NA)) +
  theme_modern() +
  scale_y_log10(breaks = 10**seq(0, 5), labels = function(x) sprintf("%g", x)) +
  scale_fill_manual(values = colors, guide = "none") +
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1)) +
  labs(x = NULL, y = "Computation Time")
```




```{r time1, message=FALSE, warning=FALSE}
dfsummary <- df |>
  filter(!Index %in% c("SD", "Length", "Noise", "Random")) |>
  mutate(Duration = Duration * 10000) |>
  group_by(Index, Length) |>
  summarize(
    CI_low = median(Duration) - sd(Duration),
    CI_high = median(Duration) + sd(Duration),
    Duration = median(Duration)
  )
dfsummary$CI_low[dfsummary$CI_low < 0] <- 0


dfsummary |>
  ggplot(aes(x = Index, y = Duration)) +
  # geom_hline(yintercept = c(0.001, 0.01, 0.1, 1), linetype = "dotted") +
  geom_line(aes(alpha = Length, group = Length)) +
  geom_point(aes(color = Length)) +
  theme_modern() +
  scale_y_log10(breaks = 10**seq(0, 4), labels = function(x) sprintf("%g", x)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  guides(alpha = "none") +
  labs(y = "Time to compute", x = NULL, color = "Signal length")
```


```{r time2, message=FALSE, warning=FALSE, include=FALSE, eval=FALSE}
df |>
  filter(!Index %in% c("SD", "Length", "Noise", "Random")) |>
  mutate(Duration = Duration * 10000) |>
  ggplot(aes(x = as.factor(Length), y = Duration)) +
  # geom_hline(yintercept = c(0.001, 0.01, 0.1, 1), linetype = "dotted") +
  geom_line(data = dfsummary, aes(group = 1)) +
  geom_violin(aes(fill = Length)) +
  facet_wrap(~Index) +
  scale_y_log10(breaks = 10**seq(0, 4), labels = function(x) sprintf("%g", x)) +
  scale_fill_viridis_c(guide = "none") +
  theme_modern() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
```



### Sensitivity to Signal Length


```{r message=FALSE, warning=FALSE, include=FALSE, eval=FALSE}
model <- lm(Result ~ Index / poly(Length, 2), data = filter(df, !Index %in% c("SD", "Length", "Noise", "Random")))

parameters::parameters(model, keep = "poly.*1") |>
  arrange(desc(abs(Coefficient))) |>
  filter(p < .05)

estimate_relation(model) |>
  ggplot(aes(x = Length, y = Predicted)) +
  geom_ribbon(aes(ymin = CI_low, ymax = CI_high, fill = Index), alpha = 0.1) +
  geom_line(aes(color = Index)) +
  geom_point2(
    data = filter(df, Index != "SD"),
    aes(y = Result, color = Index),
    alpha = 0.1, size = 2
  ) +
  scale_fill_manual(values = colors) +
  scale_color_manual(values = colors) +
  theme(legend.position = "none") +
  facet_wrap(~Index, scales = "free")
```

### Sensitivity to Noise

```{r message=FALSE, warning=FALSE, include=FALSE, eval=FALSE}
model <- lm(Result ~ Index / poly(Noise_Intensity, 2), data = filter(df, !Index %in% c("SD", "Length", "Noise", "Random")))

parameters::parameters(model, keep = "poly.*1") |>
  arrange(abs(p)) |>
  filter(p < .05)

estimate_relation(model) |>
  ggplot(aes(x = Noise_Intensity, y = Predicted)) +
  geom_ribbon(aes(ymin = CI_low, ymax = CI_high, fill = Index), alpha = 0.1) +
  geom_line(aes(color = Index)) +
  geom_point2(
    data = filter(df, Index != "SD"),
    aes(y = Result, color = Index),
    alpha = 0.1, size = 2
  ) +
  scale_fill_manual(values = colors) +
  scale_color_manual(values = colors) +
  theme(legend.position = "none") +
  facet_wrap(~Index, scales = "free_y")
```


### Correlation


```{r message=FALSE, warning=FALSE, fig.width=16, fig.height=15, cache=TRUE}
data <- df |>
  mutate(i = paste(Signal, Length, Noise_Type, Noise_Intensity, sep = "__")) |>
  select(i, Index, Result) |>
  pivot_wider(names_from = "Index", values_from = "Result") |>
  select(-i)



get_cor <- function(data, plot=FALSE) {
  cor <- correlation::correlation(data, method = "spearman", redundant = TRUE) |>
    correlation::cor_sort(hclust_method = "ward.D2")
  p <- cor |>
    cor_lower() |>
    mutate(
      Text = insight::format_value(rho, zap_small = TRUE, digits = 3),
      Text = str_replace(str_remove(Text, "^0+"), "^-0+", "-"),
      Parameter2 = fct_rev(Parameter2)
    ) |>
    ggplot(aes(x = Parameter2, y = Parameter1)) +
    geom_tile(aes(fill = rho)) +
    # geom_text(aes(label = Text), size = 2) +
    scale_fill_gradient2(low = "#2196F3", mid = "white", high = "#F44336", midpoint = 0, limit = c(-1, 1), space = "Lab", name = "Correlation", guide = "legend") +
    scale_x_discrete(expand = c(0, 0)) +
    scale_y_discrete(expand = c(0, 0)) +
    labs(title = "Correlation Matrix of Complexity Indices", x = NULL, y = NULL) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 90, hjust = 1),
      plot.title = element_text(hjust = 0.5),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank()
    )
  if(plot) plot(p)
  cor
}


cor <- get_cor(data)
```

### Duplicates

- **CREn (B)**, and **ShanEn (B)**
  - Remove *CREn (B)*  because it's slower.
- **CREn (D)**, **PFD (D)** and **ShanEn (D)**
  - Remove *CREn (D)* and *ShanEn (D)* because it's slower.
- **CREn (r)**, **PFD (r)** and **ShanEn (r)**
  - Remove *CREn (r)* and *ShanEn (r)* because it's slower.
- **PSDFD (Hasselman2013)** and **PSDFD (Voss1998)**
  - Remove **PSDFD (Voss1998)** because it's positively correlated with the rest.
- **RangeEn (A)**, **RangeEn (Ac)** and **RangeEn (B)**
  - Remove **RangeEn (A)**, **RangeEn (Ac)**  because they yield undefined entropies.
- **SVDEn**, and **FI**
  - Remove **FI**  because it's negatively correlated with the rest.
- **MMSEn**, and **IMSEn**
  - Remove **MMSEn**  because it's slower.
- **H (corrected)**, and **H (uncorrected)**
  - Remove **H (corrected)**  because it's slower.
- **FuzzyEn**, and **FuzzyApEn**
  - Remove **FuzzyApEn**  because it's slower.
- **SVDEn**, and **FuzzycApEn**
  - Remove **FuzzycApEn**  because it's slower.
- **CPEn**, and **CRPEn**
  - Remove **CPEn**  to keep the Renyi entropy.
- **NLDFD**, and **RR**
  - Remove **RR**  because it's slower.


```{r message=FALSE, warning=FALSE, include=FALSE, eval=FALSE, cache=TRUE}
cor |>
  cor_lower() |>
  filter(Parameter1 %in% names(data), Parameter2 %in% names(data)) |>
  arrange(desc(abs(rho)), Parameter1) |>
  filter(Parameter1 != Parameter2) |>
  filter(abs(rho) > .97) |>
  select(Parameter1, Parameter2, rho)


# Duplicates
# ===========
averagetime <- arrange(summarize(group_by(df, Index), Duration = mean(Duration)), Duration)

filter(averagetime, Index %in% c("CREn (D)", "PFD (D)", "ShanEn (D)"))
filter(averagetime, Index %in% c("ShanEn (B)", "CREn (B)"))
filter(averagetime, Index %in% c("ShanEn (r)", "PFD (r)", "CREn (r)"))
filter(averagetime, Index %in% c("ShanEn (C)", "PFD (C)", "CREn (C)"))
filter(averagetime, Index %in% c("SVDEn", "FI"))
filter(averagetime, Index %in% c("PSDFD (Hasselman2013)", "PSDFD (Voss1998)"))
filter(averagetime, Index %in% c("MMSEn", "IMSEn"))
filter(averagetime, Index %in% c("H (corrected)", "H (uncorrected)"))
filter(averagetime, Index %in% c("FuzzyEn", "FuzzyApEn"))
filter(averagetime, Index %in% c("SVDEn", "FuzzycApEn"))
filter(averagetime, Index %in% c("CPEn", "CRPEn"))
filter(averagetime, Index %in% c("NLDFD", "RR"))
```


```{r message=FALSE, warning=FALSE, cache=TRUE, fig.width=16, fig.height=15}
data <- data |>
  select(
    -`CREn (B)`,
    -`CREn (D)`, -`ShanEn (D)`,
    -`CREn (r)`, -`ShanEn (r)`,
    # -`CREn (C)`, -`ShanEn (C)`,
    -`PSDFD (Voss1998)`,
    -`RangeEn (A)`, -`RangeEn (Ac)`,
    -FI,
    -MMSEn,
    -`H (corrected)`,
    -FuzzyApEn,
    -FuzzycApEn,
    -CPEn,
    -RR,
    -MFDFA_HDelta,
    # -FuzzyRCMSEn,
    # -`CREn (1000)`, 
    -`CREn (100)`,
    -RQA_VEn, -RQA_LEn
  )

cor <- get_cor(data, plot=TRUE)
```

<!-- ### Hierarchical CLustering -->


<!-- ```{r message=FALSE, warning=FALSE} -->
<!-- n <- parameters::n_clusters(as.data.frame(t(data)), standardize = FALSE) -->
<!-- plot(n) -->

<!-- rez <- parameters::cluster_analysis(as.data.frame(t(data)),  -->
<!--                                     standardize = FALSE,  -->
<!--                                     n=4,  -->
<!--                                     method="hclust",  -->
<!--                                     hclust_method="ward.D2") -->
<!-- # plot(rez) -->

<!-- attributes(rez)$model |>  -->
<!--   plot(hang = -1) -->
<!-- ``` -->

### Factor Analysis

```{r message=FALSE, warning=FALSE, fig.width=14, fig.height=7}
r <- correlation::cor_smooth(as.matrix(cor))

plot(parameters::n_factors(data, cor = r))
```


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=18}
rez <- parameters::factor_analysis(data, cor = r, n = 4, rotation = "varimax", sort = TRUE, fm="ml")
# rez <- parameters::principal_components(data, n = 13, sort = TRUE)
# rez

col <- gsub('[[:digit:]]+', '', names(rez)[2])
closest <- colnames(select(rez, starts_with(col)))[apply(select(rez, starts_with(col)), 1, \(x) which.max(abs(x)))]

loadings <- attributes(rez)$loadings_long |>
  mutate(
    Loading = Loading,
    Component = fct_relevel(Component, rev(names(select(rez, starts_with(col))))),
    Variable = fct_rev(fct_relevel(Variable, rez$Variable))
  )

colors <- setNames(see::palette_material("rainbow")(length(levels(loadings$Component))), levels(loadings$Component))


p1 <- loadings |>
  # filter(Variable == "CD") |>
  ggplot(aes(x = Variable, y = Loading)) +
  geom_bar(aes(fill = Component), stat = "identity") +
  geom_vline(xintercept = c("SD", "Length", "Noise", "Random"), color = "red") +
  geom_vline(xintercept = head(cumsum(table(closest)[levels(loadings$Component)]), -1) + 0.5) +
  scale_y_continuous(expand = c(0, 0)) +
  scale_fill_material_d("rainbow") +
  coord_flip() +
  theme_minimal() +
  guides(fill = guide_legend(reverse = TRUE)) +
  labs(x = NULL) +
  theme(
    axis.text.y = element_text(
      color = rev(colors[closest]),
      face = rev(ifelse(rez$Variable %in% c("SD", "Length", "Noise", "Random"), "italic", "plain")),
      hjust = 0.5
    ),
    axis.text.x = element_blank(),
    plot.title = element_text(hjust = 0.5),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  )

p2 <- order |>
  mutate(Duration = 1 + Duration * 10000) |>
  filter(Index %in% loadings$Variable) |>
  mutate(Index = fct_relevel(Index, levels(loadings$Variable)),
         Duration = ifelse(is.na(Duration), 0, Duration)) |>
  ggplot(aes(x = log10(Duration), y = Index)) +
  geom_bar(aes(fill = log10(Duration)), stat = "identity") +
  geom_hline(yintercept = head(cumsum(sort(table(closest))), -1) + 0.5) +
  scale_x_reverse(expand = c(0, 0)) +
  # scale_x_log10(breaks = 10**seq(0, 4), labels = function(x) sprintf("%g", x), expand=c(0, 0)) +
  scale_y_discrete(position = "right") +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Computation Time", y = NULL) +
  theme_minimal() +
  theme(
    axis.text.y = element_blank(),
    axis.text.x = element_blank(),
    plot.title = element_text(hjust = 0.5),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  )

(p2 | p1) + patchwork::plot_annotation(title = "Computation Time and Factor Loading", theme = theme(plot.title = element_text(hjust = 0.5, face = "bold")))
```


## References
