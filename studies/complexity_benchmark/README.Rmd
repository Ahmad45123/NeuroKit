---
output: 
  github_document:
    toc: false
    fig_width: 10.08
    fig_height: 6
tags: [r, complexity]
vignette: >
  %\VignetteIndexEntry{README}
  \usepackage[utf8]{inputenc}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
bibliography: bibliography.bib
csl: utils/apa.csl
---

```{r, echo = FALSE, warning=FALSE, message=FALSE}
# options and parameters
options(digits=3)

knitr::opts_chunk$set(
  collapse = TRUE,
  dpi=450,
  fig.path = "../../studies/complexity_benchmark/figures/"
)
```



<!-- # Benchmarking and Analysis of Complexity Measures -->
# Measuring Chaos: Complexity and Fractal Physiology using NeuroKit2

*This study can be referenced by* [*citing the package and the documentation*](https://neuropsychology.github.io/NeuroKit/cite_us.html).

**We'd like to improve this study, but unfortunately we currently don't have the time. If you want to help to make it happen, please contact us!**

## Introduction

The goal for NeuroKit is to provide the most comprehensive, accurate and fastest base Python implementations of complexity indices (fractal dimension, entropy, etc.).

## Methods

### Data Generation

The script to generate the data can be found at ...

Generated 3 types of signals, to which we added different types of noise.

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(easystats)
library(patchwork)

df <- read.csv("data_Signals.csv") |> 
  mutate(Method = as.factor(Method),
         Noise = as.factor(Noise),
         Intensity = as.factor(insight::format_value(Noise_Intensity)))

df <- df |> 
  filter(Intensity %in% levels(df$Intensity)[c(1, round(length(levels(df$Intensity)) / 2), length(levels(df$Intensity)))])

make_plot <- function(method = "Random-Walk", title = "Random-Walk", color = "red") {
  df |>
    filter(Method == method) |> 
    ggplot(aes(x = Duration, y = Signal)) + 
    geom_line(color = color) +
    ggside::geom_ysidedensity(aes(x=stat(density))) +
    facet_grid(Intensity ~ Noise, labeller = label_both) +
    labs(y = NULL, title = title) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5),
          ggside.panel.border = element_blank(),
          ggside.panel.grid =element_blank(),
          ggside.panel.background = element_blank()) 
}

p1 <- make_plot(method = "Random-Walk", title = "Random-Walk", color = "red") 
p2 <- make_plot(method = "lorenz_10_2.5_28", title = "Lorenz (sigma=10, beta=2.5, rho=28)", color = "blue") 
p3 <- make_plot(method = "lorenz_20_2_30", title = "Lorenz (sigma=20, beta=2, rho=30)", color = "green") 
p4 <- make_plot(method = "oscillatory", title = "Oscillatory", color = "orange") 

p1 / p2 / p3 / p4 + patchwork::plot_annotation(title = "Examples of Simulated Signals", theme = theme(plot.title = element_text(face = "bold", hjust = 0.5)))
```


## Results


```{r message=FALSE, warning=FALSE}
df <- read.csv("data_Complexity.csv") |> 
  mutate(Method = as.factor(Method)) 

# Show and filter out NaNs
df[is.na(df$Result), "Index"]
df <- filter(df, !is.na(Result))

df[is.infinite(df$Result), "Index"]
df <- filter(df, !is.infinite(Result))

df <- df |> 
  group_by(Index) |> 
  standardize(select="Result") |> 
  ungroup()
```

```{r message=FALSE, warning=FALSE, include=FALSE}
colors = c("SD" = "red", 
           "Diff" = "red", 
           
           "PFD (A)" = "#2196F3", 
           "PFD (B)" = "#2196F3", 
           "PFD (C)" = "#2196F3", 
           "PFD (D)" = "#2196F3",
           "PFD (r)" = "#2196F3",
           "PFD (3)" = "#2196F3",
           "PFD (10)" = "#2196F3",
           "PFD (100)" = "#2196F3",
           "PFD (1000)" = "#2196F3",
           "KFD" = "#2196F3",
           "SFD" = "#2196F3",
           "SDAFD" = "#2196F3",
           "NLDFD" = "#2196F3",
           "PSDFD (Voss1998)" = "#2196F3",
           "PSDFD (Hasselman2013)" = "#2196F3",
           "HFD" = "#2196F3",
           
           "SVDEn" = "#E91E63",
           "AttEn" = "#E91E63",
           "DiffEn" = "#E91E63",
           "ApEn" = "#E91E63",
           "cApEn" = "#E91E63",
           "PEn" = "#E91E63",
           "SPEn" = "#E91E63",
           "MSPEn" = "#E91E63",
           "WPEn" = "#E91E63",
           "SampEn" = "#E91E63",
           "FuzzyEn" = "#E91E63",
           "FuzzyApEn" = "#E91E63",
           "FuzzycApEn" = "#E91E63",
           "MSEn" = "#E91E63",
           "CMSEn" = "#E91E63",
           "RCMSEn" = "#E91E63",
           "MMSEn" = "#E91E63",
           "IMSEn" = "#E91E63",
           "ShanEn (A)" = "#E91E63",
           "ShanEn (B)" = "#E91E63",
           "ShanEn (C)" = "#E91E63",
           "ShanEn (D)" = "#E91E63",
           "ShanEn (r)" = "#E91E63",
           "ShanEn (3)" = "#E91E63",
           "ShanEn (10)" = "#E91E63",
           "ShanEn (100)" = "#E91E63",
           "ShanEn (1000)" = "#E91E63",
           "CREn (A)" = "#E91E63",
           "CREn (B)" = "#E91E63",
           "CREn (C)" = "#E91E63",
           "CREn (D)" = "#E91E63",
           "CREn (r)" = "#E91E63",
           "CREn (3)" = "#E91E63",
           "CREn (10)" = "#E91E63",
           "CREn (100)" = "#E91E63",
           "CREn (1000)" = "#E91E63",
           "RangeEn (A)" = "#E91E63",
           "RangeEn (Ac)" = "#E91E63",
           "RangeEn (B)" = "#E91E63",
           
           "H (corrected)" = "#2196F3",
           "H (uncorrected)" = "#2196F3",
           "LZC" = "#2196F3",
           "PLZC" = "#2196F3",
           "RR" = "#2196F3",
           "FI" = "#FF5722",
           "CD" = "#FF5722",
           "Hjorth" = "#FF5722")

# unique(df$Index)[!unique(df$Index) %in% names(colors)]
```




### Computation Time

```{r message=FALSE, warning=FALSE}
order <- df |> 
  group_by(Index) |> 
  summarize(Duration = median(Duration)) |> 
  arrange(Duration) |> 
  mutate(Index = factor(Index, levels = Index))

df <- mutate(df, Index = fct_relevel(Index, as.character(order$Index)))

df |> 
  filter(!Index %in% c("Diff", "SD")) |> 
  mutate(Duration = Duration * 10000) |> 
  ggplot(aes(x = Index, y = Duration)) +
  # geom_violin(aes(fill = Index)) +
  geom_hline(yintercept = rep(10, 5)**seq(0, 4), linetype = "dotted") +
  ggdist::stat_slab(side = "bottom", aes(fill = Index), adjust = 3) +
  ggdist::stat_dotsinterval(aes(fill = Index, slab_size = NA)) +
  theme_modern() +
  scale_y_log10(breaks = rep(10, 5)**seq(0, 4), labels = function(x) sprintf("%g", x)) +
  scale_fill_manual(values = colors, guide = "none") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  labs(x = NULL, y = "Computation Time")
```




```{r time1, message=FALSE, warning=FALSE}
dfsummary <- df |>
  filter(!Index %in% c("Diff", "SD")) |> 
  mutate(Duration = Duration * 10000) |> 
  group_by(Index, Length) |>
  summarize(CI_low = median(Duration) - sd(Duration),
            CI_high = median(Duration) + sd(Duration),
            Duration = median(Duration))
dfsummary$CI_low[dfsummary$CI_low < 0] <- 0


dfsummary |>
  ggplot(aes(x = Index, y = Duration)) + 
  # geom_hline(yintercept = c(0.001, 0.01, 0.1, 1), linetype = "dotted") +
  geom_line(aes(alpha = Length, group = Length)) +
  geom_point(aes(color = Length)) + 
  theme_modern() +
  scale_y_log10(breaks = rep(10, 5)**seq(0, 4), labels = function(x) sprintf("%g", x)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  guides(alpha = "none") +
  labs(y = "Time to compute", x = NULL, color = "Signal length")
```


```{r time2, message=FALSE, warning=FALSE}
df |> 
  filter(!Index %in% c("Diff", "SD")) |> 
  mutate(Duration = Duration * 10000) |> 
  ggplot(aes(x = as.factor(Length), y = Duration)) +
  # geom_hline(yintercept = c(0.001, 0.01, 0.1, 1), linetype = "dotted") +
  geom_line(data=dfsummary, aes(group = 1)) +
  geom_violin(aes(fill = Length)) +
  facet_wrap(~Index) +
  scale_y_log10(breaks = rep(10, 5)**seq(0, 4), labels = function(x) sprintf("%g", x)) +
  scale_fill_viridis_c(guide = "none") +
  theme_modern() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
```



### Sensitivity to Signal Length


```{r message=FALSE, warning=FALSE}
model <- lm(Result ~ Index / poly(Length, 2), data = filter(df, Index != "SD"))

parameters::parameters(model, keep = "poly.*1") |> 
  arrange(desc(abs(Coefficient))) |> 
  filter(p < .05)

estimate_relation(model) |> 
  ggplot(aes(x = Length, y = Predicted)) +
  geom_ribbon(aes(ymin = CI_low, ymax = CI_high, fill = Index), alpha = 0.1) +
  geom_line(aes(color = Index)) +
  geom_point2(data = filter(df, Index != "SD"), 
              aes(y = Result, color = Index), 
              alpha=0.1, size=2) +
  scale_fill_manual(values = colors) +
  scale_color_manual(values = colors) +
  theme(legend.position = "none") +
  facet_wrap(~Index, scales = "free")
```

### Sensitivity to Noise

```{r message=FALSE, warning=FALSE}
model <- lm(Result ~ Index / poly(Noise_Intensity, 2), data = filter(df, Index != "SD"))

parameters::parameters(model, keep = "poly.*1") |> 
  arrange(abs(p)) |> 
  filter(p < .05)

estimate_relation(model) |> 
  ggplot(aes(x = Noise_Intensity, y = Predicted)) +
  geom_ribbon(aes(ymin = CI_low, ymax = CI_high, fill = Index), alpha = 0.1) +
  geom_line(aes(color = Index)) +
  geom_point2(data = filter(df, Index != "SD"), 
              aes(y = Result, color = Index), 
              alpha=0.1, size=2) +
  scale_fill_manual(values = colors) +
  scale_color_manual(values = colors) +
  theme(legend.position = "none") +
  facet_wrap(~Index, scales = "free_y")
```

### Correlation


```{r message=FALSE, warning=FALSE}
data <- df |> 
  mutate(i = paste(Signal, Length, Noise, Noise_Intensity, sep = "__")) |> 
  select(i, Index, Result) |> 
  pivot_wider(names_from = "Index", values_from = "Result") |> 
  select(-i) 


cor_lower <- function(cor) {
  m <- as.matrix(cor)
  
  tri <- upper.tri(m, diag = FALSE)
  rownames(tri) <- rownames(m)
  colnames(tri) <- colnames(m)
  
  toremove <- c()
  
  for(param1 in rownames(m)) {
    for(param2 in colnames(m)) {
      if(tri[param1, param2] == FALSE) {
        toremove <- c(toremove, which(cor$Parameter1 == param1 & cor$Parameter2 == param2))
      }
    } 
  }

  cor[-toremove, ]
}



get_cor <- function(data) {
  cor <- correlation::correlation(data, method = "spearman", redundant = TRUE) |> 
    cor_sort(hclust_method = "ward.D2")
  p <- cor |> 
    cor_lower() |> 
    mutate(Text = insight::format_value(rho, zap_small=TRUE, digits = 3),
           Text = str_replace(str_remove(Text, "^0+"), "^-0+", "-"),
           Parameter2 = fct_rev(Parameter2)) |> 
    ggplot(aes(x = Parameter2, y=Parameter1)) +
    geom_tile(aes(fill = rho)) +
    # geom_text(aes(label = Text), size = 2) +
    scale_fill_gradient2(low = '#2196F3', mid = 'white', high = '#F44336', midpoint = 0, limit = c(-1, 1), space = 'Lab', name = 'Correlation', guide = 'legend') +
    scale_x_discrete(expand = c(0, 0)) +
    scale_y_discrete(expand = c(0, 0)) +
    labs(title = "Correlation Matrix of Complexity Indices", x = NULL, y = NULL) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle=45, hjust = 1),
          plot.title = element_text(hjust = 0.5),
          panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank()) 
  plot(p)
  cor
}


cor <- get_cor(data)
```

### Duplicates 

- **CREn (B)**, and **ShanEn (B)**
  - Remove *CREn (B)*  because it's slower.
- **CREn (D)**, **PFD (D)** and **ShanEn (D)**
  - Remove *CREn (D)* and *ShanEn (D)* because it's slower.
- **CREn (r)**, **PFD (r)** and **ShanEn (r)**
  - Remove *CREn (r)* and *ShanEn (r)* because it's slower.
- **PSDFD (Hasselman2013)** and **PSDFD (Voss1998)**
  - Remove **PSDFD (Voss1998)** because it's positively correlated with the rest.
- **RangeEn (A)**, **RangeEn (Ac)** and **RangeEn (B)**
  - Remove **RangeEn (A)**, **RangeEn (Ac)**  because they yield undefined entropies.
- **SVDEn**, and **FI**
  - Remove **FI**  because it's negatively correlated with the rest.


```{r message=FALSE, warning=FALSE}
cor |> 
  cor_lower() |> 
  arrange(desc(abs(rho)), Parameter1) |> 
  filter(Parameter1 != Parameter2) |> 
  filter(abs(rho) > .98)


# Duplicates 
# ===========
averagetime <- arrange(summarize(group_by(df, Index), Duration = mean(Duration)), Duration)

filter(averagetime, Index %in% c("CREn (D)", "PFD (D)", "ShanEn (D)"))
filter(averagetime, Index %in% c("ShanEn (B)", "CREn (B)"))
filter(averagetime, Index %in% c("ShanEn (r)", "PFD (r)", "CREn (r)"))
filter(averagetime, Index %in% c("SVDEn", "FI"))
filter(averagetime, Index %in% c("PSDFD (Hasselman2013)", "PSDFD (Voss1998)"))

# NLFD | RR
# NLFD | RR
# - Drop RR because it's slower
# H (uncorrected) | H (corrected)
# - ??
# SVDEn | FuzzyEn
# - Drop FuzzyEn because it's slower

# Hasselman positively correlated with most of the others
# - RR: much slower



data <- data |> 
  select(
    - `CREn (B)`,
    -`CREn (D)`, -`ShanEn (D)`,
    - `CREn (r)`, -`ShanEn (r)`,
    -`PSDFD (Voss1998)`,
    -`RangeEn (A)`, -`RangeEn (Ac)`,
    -FI,
  )

cor <- get_cor(data)
```


### Hierarchical CLustering


```{r message=FALSE, warning=FALSE}
n <- parameters::n_clusters(as.data.frame(t(data)), standardize = FALSE)
plot(n)

rez <- parameters::cluster_analysis(as.data.frame(t(data)), 
                                    standardize = FALSE, 
                                    n=4, 
                                    method="hclust", 
                                    hclust_method="ward.D2")
# plot(rez)

attributes(rez)$model |> 
  plot(hang = -1)
```

### Factor Analysis


```{r message=FALSE, warning=FALSE}
plot(parameters::n_factors(data))
rez <- parameters::factor_analysis(data, cor = as.matrix(cor), n = 4, rotation = "varimax", sort = TRUE)
rez

plot(rez)
```


## References
