---
output: 
  github_document:
    toc: false
    fig_width: 10.08
    fig_height: 6
tags: [r, complexity]
vignette: >
  %\VignetteIndexEntry{README}
  \usepackage[utf8]{inputenc}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
bibliography: bibliography.bib
csl: utils/apa.csl
---

```{r, echo = FALSE, warning=FALSE, message=FALSE}
# options and parameters
options(digits=3)

knitr::opts_chunk$set(
  collapse = TRUE,
  dpi=450,
  fig.path = "../../studies/complexity_benchmark/figures/"
)
```



<!-- # Benchmarking and Analysis of Complexity Measures -->
# Measuring Chaos: Complexity and Fractal Physiology using NeuroKit2

*This study can be referenced by* [*citing the package and the documentation*](https://neuropsychology.github.io/NeuroKit/cite_us.html).

**We'd like to improve this study, but unfortunately we currently don't have the time. If you want to help to make it happen, please contact us!**

## Introduction

The goal for NeuroKit is to provide the most comprehensive, accurate and fastest base Python implementations of complexity indices (fractal dimension, entropy, etc.).

## Methods

### Data Generation

The script to generate the data can be found at ...

Generated 3 types of signals, to which we added different types of noise.

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(easystats)
library(patchwork)

df <- read.csv("data_Signals.csv") |> 
  mutate(Method = as.factor(Method),
         Noise = as.factor(Noise),
         Intensity = as.factor(insight::format_value(Noise_Intensity)))

df <- df |> 
  filter(Intensity %in% levels(df$Intensity)[c(1, round(length(levels(df$Intensity)) / 2), length(levels(df$Intensity)))])

make_plot <- function(method = "Random-Walk", title = "Random-Walk", color = "red") {
  df |>
    filter(Method == method) |> 
    ggplot(aes(x = Duration, y = Signal)) + 
    geom_line(color = color) +
    ggside::geom_ysidedensity(aes(x=stat(density))) +
    facet_grid(Intensity ~ Noise, labeller = label_both) +
    labs(y = NULL, title = title) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5),
          ggside.panel.border = element_blank(),
          ggside.panel.grid =element_blank(),
          ggside.panel.background = element_blank()) 
}

p1 <- make_plot(method = "Random-Walk", title = "Random-Walk", color = "red") 
p2 <- make_plot(method = "lorenz_10_2.5_28", title = "Lorenz (sigma=10, beta=2.5, rho=28)", color = "blue") 
p3 <- make_plot(method = "lorenz_20_2_30", title = "Lorenz (sigma=20, beta=2, rho=30)", color = "green") 

p1 / p2 / p3 + patchwork::plot_annotation(title = "Examples of Simulated Signals", theme = theme(plot.title = element_text(face = "bold", hjust = 0.5)))
```


## Results

### Average Computation Time

```{r message=FALSE, warning=FALSE}
df <- read.csv("data_Complexity.csv") |> 
  mutate(Method = as.factor(Method)) 

# Show and filter out NaNs
df[is.na(df$Result), "Index"]
df <- filter(df, !is.na(Result))


colors = c("PFD (A)" = "#2196F3", 
           "PFD (B)" = "#2196F3", 
           "PFD (C)" = "#2196F3", 
           "PFD (D)" = "#2196F3",
           "KFD" = "#2196F3",
           "SFD" = "#2196F3",
           "SDAFD" = "#2196F3",
           "NLDFD" = "#2196F3",
           "PSDFD (Voss1998)" = "#2196F3",
           "PSDFD (Hasselman2013)" = "#2196F3",
           "HFD" = "#2196F3",
           
           "SVDEn" = "#E91E63",
           "DiffEn" = "#E91E63",
           "ApEn" = "#E91E63",
           "PEn" = "#E91E63",
           "SPEn" = "#E91E63",
           "MSPEn" = "#E91E63",
           "WPEn" = "#E91E63",
           "SampEn" = "#E91E63",
           "MSEn" = "#E91E63",
           "FuzzyEn" = "#E91E63",
           "ShanEn3" = "#E91E63",
           "ShanEn10" = "#E91E63",
           "ShanEn100" = "#E91E63",
           "ShanEn1000" = "#E91E63",
           "CREn3" = "#E91E63",
           "CREn10" = "#E91E63",
           "CREn100" = "#E91E63",
           "CREn1000" = "#E91E63",
           
           "H (corrected)" = "#2196F3",
           "H (uncorrected)" = "#2196F3",
           "LZC" = "#2196F3",
           "PLZC" = "#2196F3",
           "RR" = "#2196F3",
           "FI" = "#FF5722",
           "CD" = "#FF5722",
           "Hjorth" = "#FF5722")

# unique(df$Index)[!unique(df$Index) %in% names(colors)]
```


```{r message=FALSE, warning=FALSE}
order <- df |> 
  group_by(Index) |> 
  summarize(Duration = median(Duration)) |> 
  arrange(Duration) |> 
  mutate(Index = factor(Index, levels = Index))

df <- mutate(df, Index = fct_relevel(Index, as.character(order$Index)))

df |> 
  ggplot(aes(x = Index, y = Duration)) +
  # geom_violin(aes(fill = Index)) +
  ggdist::stat_slab(side = "bottom", aes(fill = Index), adjust = 3) +
  ggdist::stat_dotsinterval(aes(fill = Index, slab_size = NA)) +
  theme_modern() +
  scale_y_log10() +
  scale_fill_manual(values = colors, guide = "none") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  labs(x = NULL, y = "Computation Time")
```

### Sensitivity to Signal Length

#### Computation Time

```{r time1, message=FALSE, warning=FALSE}
dfsummary <- df |>
  mutate(Duration = Duration * 10000) |> 
  group_by(Index, Length) |>
  summarize(CI_low = median(Duration) - sd(Duration),
            CI_high = median(Duration) + sd(Duration),
            Duration = median(Duration))
dfsummary$CI_low[dfsummary$CI_low < 0] <- 0


dfsummary |>
  ggplot(aes(x = Index, y = Duration)) + 
  # geom_hline(yintercept = c(0.001, 0.01, 0.1, 1), linetype = "dotted") +
  geom_line(aes(alpha = Length, group = Length)) +
  geom_point(aes(color = Length)) + 
  theme_modern() +
  scale_y_log10(breaks = rep(10, 5)**seq(0, 4), labels = function(x) sprintf("%g", x)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  guides(alpha = "none") +
  labs(y = "Time to compute", x = NULL, color = "Signal length")
```


```{r time2, message=FALSE, warning=FALSE}
df |> 
  mutate(Duration = Duration * 10000) |> 
  ggplot(aes(x = as.factor(Length), y = Duration)) +
  # geom_hline(yintercept = c(0.001, 0.01, 0.1, 1), linetype = "dotted") +
  geom_line(data=dfsummary, aes(group = 1)) +
  geom_violin(aes(fill = Length)) +
  facet_wrap(~Index) +
  scale_y_log10(breaks = rep(10, 5)**seq(0, 4), labels = function(x) sprintf("%g", x)) +
  scale_fill_viridis_c(guide = "none") +
  theme_modern() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
```


#### Results

```{r message=FALSE, warning=FALSE}
model <- lm(Result ~ Index / poly(Length, 3), data = df)

parameters::parameters(model, keep = "poly") |> 
  arrange(desc(abs(Coefficient))) |> 
  filter(p < .05)

estimate_relation(model) |> 
  ggplot(aes(x = Length, y = Predicted)) +
  geom_ribbon(aes(ymin = CI_low, ymax = CI_high, fill = Index), alpha = 0.1) +
  geom_line(aes(color = Index)) +
  geom_point(data = df, aes(y = Result, color = Index)) + 
  scale_fill_manual(values = colors) +
  scale_color_manual(values = colors) +
  facet_wrap(~Index, scales = "free")
```




### Correlation


```{r message=FALSE, warning=FALSE}
data <- df |> 
  mutate(i = paste(Signal, Length, Noise, Noise_Intensity, sep = "__")) |> 
  select(i, Index, Result) |> 
  pivot_wider(names_from = "Index", values_from = "Result") |> 
  select(-i) 

cor <- correlation::correlation(data, method = "spearman", redundant = TRUE) |> 
  cor_sort(hclust_method = "ward.D2")

cor_lower <- function(cor) {
  m <- as.matrix(cor)
  
  tri <- upper.tri(m, diag = FALSE)
  rownames(tri) <- rownames(m)
  colnames(tri) <- colnames(m)
  
  toremove <- c()
  
  for(param1 in rownames(m)) {
    for(param2 in colnames(m)) {
      if(tri[param1, param2] == FALSE) {
        toremove <- c(toremove, which(cor$Parameter1 == param1 & cor$Parameter2 == param2))
      }
    } 
  }

  cor[-toremove, ]
}

cor |> 
  cor_lower() |> 
  mutate(Text = str_remove(insight::format_value(rho, zap_small=TRUE, digits = 3), "^0+"),
         Parameter2 = fct_rev(Parameter2)) |> 
  ggplot(aes(x = Parameter2, y=Parameter1)) +
  geom_tile(aes(fill = rho)) +
  geom_text(aes(label = Text), size = 3) +
  scale_fill_gradient2(low = '#2196F3', mid = 'white', high = '#F44336', midpoint = 0, limit = c(-1, 1), space = 'Lab', name = 'Correlation', guide = 'legend') +
  scale_x_discrete(expand = c(0, 0)) +
  scale_y_discrete(expand = c(0, 0)) +
  labs(title = "Correlation Matrix of Complexity Indices", x = NULL, y = NULL) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle=45, hjust = 1),
        plot.title = element_text(hjust = 0.5),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) 
```

```{r message=FALSE, warning=FALSE}
cor |> 
  arrange(desc(rho)) |> 
  filter(Parameter1 != Parameter2) |> 
  filter(abs(rho) > .95)

# Duplicates 
# ===========
# NLFD | RR
# - Drop RR because it's slower
# H (uncorrected) | H (corrected)
# - ??
# SVDEn | FuzzyEn
# - Drop FuzzyEn because it's slower





data <- data |> 
  select(
    -`PSDFD (Voss1998)`,  # Hasselman positively correlated with most of the others
    -FI)  # FI is negatively correlated with the rest
# - RR: much slower
```

### Hierarchical CLustering


```{r message=FALSE, warning=FALSE}
n <- parameters::n_clusters(as.data.frame(t(data)), standardize = FALSE)
plot(n)

rez <- parameters::cluster_analysis(as.data.frame(t(data)), 
                                    standardize = FALSE, 
                                    n=7, 
                                    method="hclust", 
                                    hclust_method="ward.D2")
# plot(rez)

attributes(rez)$model |> 
  plot(hang = -1)
```

### Factor Analysis


```{r message=FALSE, warning=FALSE}
plot(parameters::n_factors(data))
rez <- parameters::factor_analysis(data, cor = cor(data, method = "spearman"), n = 6, rotation = "varimax", sort = TRUE)
rez
```


## References
